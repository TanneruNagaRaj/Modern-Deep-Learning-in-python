{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_data():\n",
    "    print(\"Transformed Data\")\n",
    "    \n",
    "    df = pd.read_csv('C:/Users/TANNERU/Downloads/train.csv/train.csv')\n",
    "    #print(df)\n",
    "    data = df.values.astype(np.float32)\n",
    "    #print(data)\n",
    "    \n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    \n",
    "    X = data[:,1:]\n",
    "    Y = data[:,0].astype(np.int32)\n",
    "    print(\"Innputs\",X)\n",
    "    print(\"output\",Y)\n",
    "    print(X.shape) #(42000, 784)\n",
    "    print(Y.shape) #(42000,)\n",
    "    \n",
    "    \n",
    "    Xtrain = X[:-1000]\n",
    "    Xtest = X[-1000:]\n",
    "    Ytrain = Y[:-1000]\n",
    "    Ytest = Y[-1000:]\n",
    "    print(\"Xtrain\",Xtrain.shape)#(41000, 784)\n",
    "    print(\"Xtest\",Xtest.shape)#(1000, 784)\n",
    "    print(\"Ytrain\",Ytrain.shape)#(41000,)\n",
    "    print(\"Ytest\",Ytest.shape) #(1000,)\n",
    "    \n",
    "    \n",
    "    mu = Xtrain.mean(axis = 0) #(784,)\n",
    "    #print(mu)\n",
    "    print(mu.shape)#(784,)\n",
    "    \n",
    "    \n",
    "    #center the data\n",
    "    Xtrain = Xtrain - mu\n",
    "    Xtest = Xtest - mu\n",
    "    #print(Xtrain)\n",
    "    #print(Xtest)\n",
    "    \n",
    "    #transforming data\n",
    "    pca = PCA()\n",
    "    Ztrain = pca.fit_transform(Xtrain)\n",
    "    Ztest = pca.transform(Xtest)\n",
    "    print(Ztrain.shape)\n",
    "    print(Ztest.shape)\n",
    "    #print(Ztrain)\n",
    "    #print(Ztest)\n",
    "    \n",
    "    #plot_cumulative_variance(pca)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Ztrain = Ztrain[:,:300]\n",
    "    Ztest = Ztest[:,:300]\n",
    "    print(Ztrain.shape) #(41000, 300)\n",
    "    print(Ztest.shape) # (1000, 300)\n",
    "    \n",
    "    \n",
    "    #normalization\n",
    "    mean = Ztrain.mean(axis = 0)\n",
    "    std = Ztrain.std(axis = 0)\n",
    "    \n",
    "    Ztrain = (Ztrain - mean)/std\n",
    "    Ztest = (Ztest - mean)/std\n",
    "    \n",
    "    \n",
    "    return Ztrain,Ztest,Ytrain,Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,w,b):\n",
    "    #softmax\n",
    "    a = X.dot(w)+b\n",
    "    expA = np.exp(a)\n",
    "    y = expA/expA.sum(axis = 1,keepdims = True)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "def predict(p_y):\n",
    "    return np.argmax(p_y,axis = 1)\n",
    "\n",
    "\n",
    "def error_rate(p_y,t):\n",
    "    prediction = predict(p_y)\n",
    "    return np.mean(prediction != t)\n",
    "\n",
    "\n",
    "def cost(p_y,t):\n",
    "    tot = -t*np.log(p_y)\n",
    "    return tot.sum()\n",
    "\n",
    "\n",
    "def gradw(t,y,X):\n",
    "    return X.T.dot(t-y)\n",
    "\n",
    "\n",
    "def gradb(t,y):\n",
    "    return (t-y).sum(axis = 0)\n",
    "\n",
    "\n",
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    y = y.astype(np.int32)\n",
    "    ind = np.zeros((N,10))\n",
    "    for i in range(N):\n",
    "        ind[i,y[i]] = 1\n",
    "    return ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "Innputs [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "output [2 7 6 ... 6 8 0]\n",
      "(42000, 784)\n",
      "(42000,)\n",
      "Xtrain (41000, 784)\n",
      "Xtest (1000, 784)\n",
      "Ytrain (41000,)\n",
      "Ytest (1000,)\n",
      "(784,)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(41000, 784)\n",
      "(1000, 784)\n",
      "[[-1.84754013e+02 -8.02726257e+02 -5.39397888e+01 ...  4.23098123e-03\n",
      "  -0.00000000e+00 -0.00000000e+00]\n",
      " [ 2.04950058e+02  8.34076477e+02 -1.27717415e+02 ... -2.35413856e-04\n",
      "  -3.37017205e-04  8.43522284e-05]\n",
      " [ 6.99396240e+02  1.53998871e+02  5.84375305e+02 ... -4.62669705e-05\n",
      "   4.62577475e-04 -2.10094353e-04]\n",
      " ...\n",
      " [ 6.00134583e+01  1.28022595e+03 -3.84951210e+01 ... -1.47300659e-06\n",
      "   7.74081798e-07 -8.85343141e-08]\n",
      " [ 3.59315033e+01  2.59208160e+02  1.92562057e+02 ...  3.97462736e-06\n",
      "   6.61593049e-07  3.30729137e-07]\n",
      " [-8.01074890e+02 -2.41091180e+00 -1.54290894e+02 ...  9.47891408e-07\n",
      "   7.38768506e-07  1.07933559e-07]]\n",
      "[[-2.4483366e+02  6.5530994e+02  2.5305870e+02 ...  3.2204882e-06\n",
      "   1.6882803e-04  6.8439571e-05]\n",
      " [ 2.5899304e+02 -1.3685269e+02  3.0136606e+02 ... -2.8915717e-06\n",
      "  -1.9319967e-05  6.6247667e-05]\n",
      " [-9.5628156e+02 -6.6105353e+02  2.5232593e+02 ... -3.0852584e-06\n",
      "  -1.3232561e-04 -4.5492885e-05]\n",
      " ...\n",
      " [ 1.1081960e+02  6.4388115e+01  1.0419060e+03 ...  2.3640391e-07\n",
      "   3.2757522e-05  5.9459275e-05]\n",
      " [-4.5863437e+02 -3.6234052e+02 -1.7666931e+02 ...  2.8946622e-06\n",
      "  -1.1898862e-05 -4.0407391e-05]\n",
      " [ 1.2885050e+03 -2.6918604e+02  3.8349255e+02 ... -5.5214923e-06\n",
      "   3.1364567e-04  1.1550348e-04]]\n",
      "(41000, 300)\n",
      "(1000, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.3193007 , -1.6175828 , -0.11742064, ..., -1.293032  ,\n",
       "          0.34524918, -1.1809012 ],\n",
       "        [ 0.35420415,  1.6807578 , -0.2780255 , ...,  1.7539368 ,\n",
       "          1.8303059 ,  2.4145687 ],\n",
       "        [ 1.2087293 ,  0.3103253 ,  1.2721133 , ..., -0.19047563,\n",
       "         -0.5807255 , -1.0350432 ],\n",
       "        ...,\n",
       "        [ 0.10371792,  2.5797987 , -0.0837995 , ..., -0.8012042 ,\n",
       "          0.07621013, -0.98067707],\n",
       "        [ 0.06209836,  0.52233374,  0.4191837 , ..., -0.51626474,\n",
       "          0.90385026, -0.11732495],\n",
       "        [-1.3844553 , -0.00485793, -0.33587274, ...,  0.5684533 ,\n",
       "         -0.614243  , -0.22335804]], dtype=float32),\n",
       " array([[-0.42313316,  1.3205231 ,  0.5508775 , ..., -0.0904577 ,\n",
       "          0.37805763, -0.7211976 ],\n",
       "        [ 0.44760376, -0.27577314,  0.65603673, ...,  1.676929  ,\n",
       "         -0.08562984, -0.17807841],\n",
       "        [-1.6526908 , -1.3320965 ,  0.5492824 , ..., -0.3737937 ,\n",
       "          0.7304006 ,  0.39699456],\n",
       "        ...,\n",
       "        [ 0.19152348,  0.12974958,  2.2681017 , ...,  0.46811137,\n",
       "          0.18426456,  1.1694806 ],\n",
       "        [-0.7926336 , -0.73015636, -0.38458782, ..., -0.07939966,\n",
       "          0.24147488, -0.1832258 ],\n",
       "        [ 2.2268546 , -0.54243964,  0.83481604, ...,  0.7304761 ,\n",
       "         -0.52228314, -0.08427023]], dtype=float32),\n",
       " array([2, 7, 6, ..., 9, 6, 9]),\n",
       " array([4, 0, 1, 7, 6, 8, 4, 1, 8, 9, 0, 8, 0, 1, 5, 5, 6, 5, 5, 5, 3, 9,\n",
       "        6, 7, 6, 1, 7, 3, 7, 8, 0, 4, 6, 3, 0, 5, 9, 8, 3, 1, 7, 3, 5, 7,\n",
       "        9, 7, 5, 0, 1, 6, 3, 6, 9, 5, 6, 8, 6, 3, 0, 4, 2, 4, 9, 1, 1, 0,\n",
       "        2, 1, 6, 7, 0, 3, 3, 2, 4, 0, 2, 9, 2, 1, 8, 1, 0, 2, 4, 6, 5, 3,\n",
       "        9, 4, 9, 5, 6, 8, 6, 4, 1, 5, 9, 9, 3, 9, 2, 1, 2, 4, 9, 9, 5, 0,\n",
       "        1, 9, 3, 6, 1, 6, 0, 1, 9, 6, 5, 7, 2, 7, 9, 3, 8, 8, 3, 7, 3, 3,\n",
       "        4, 2, 9, 7, 0, 3, 5, 7, 7, 6, 3, 8, 2, 3, 2, 3, 7, 7, 3, 1, 8, 9,\n",
       "        6, 5, 5, 5, 2, 4, 0, 5, 1, 0, 1, 6, 8, 8, 5, 6, 0, 4, 7, 1, 3, 2,\n",
       "        9, 0, 0, 3, 9, 5, 4, 3, 7, 8, 2, 0, 1, 3, 9, 0, 8, 2, 2, 8, 8, 1,\n",
       "        1, 0, 7, 6, 0, 6, 2, 2, 7, 6, 5, 8, 6, 1, 0, 0, 2, 1, 0, 8, 5, 8,\n",
       "        6, 3, 3, 1, 6, 1, 3, 8, 3, 5, 8, 2, 8, 6, 8, 2, 8, 5, 4, 3, 3, 4,\n",
       "        0, 1, 4, 7, 6, 9, 8, 6, 2, 1, 8, 0, 6, 0, 7, 6, 1, 3, 4, 1, 3, 5,\n",
       "        8, 3, 0, 7, 0, 7, 5, 9, 0, 8, 0, 4, 2, 5, 6, 4, 3, 5, 3, 4, 7, 2,\n",
       "        4, 2, 7, 9, 3, 8, 9, 1, 7, 3, 6, 1, 6, 5, 1, 5, 8, 2, 3, 5, 6, 1,\n",
       "        5, 3, 7, 4, 7, 2, 1, 4, 4, 1, 0, 5, 3, 0, 6, 7, 1, 6, 4, 4, 0, 3,\n",
       "        3, 7, 1, 9, 6, 6, 1, 3, 3, 1, 0, 3, 6, 8, 8, 2, 0, 7, 6, 1, 9, 3,\n",
       "        4, 2, 5, 4, 1, 8, 8, 3, 3, 7, 7, 6, 7, 8, 6, 5, 2, 7, 2, 1, 5, 8,\n",
       "        1, 4, 8, 7, 7, 4, 3, 1, 9, 1, 0, 6, 1, 3, 1, 6, 5, 6, 9, 5, 3, 1,\n",
       "        7, 9, 6, 0, 4, 5, 1, 3, 7, 4, 9, 3, 9, 3, 0, 0, 2, 0, 3, 3, 3, 8,\n",
       "        4, 1, 1, 4, 3, 5, 2, 2, 0, 6, 8, 0, 2, 4, 6, 0, 2, 6, 4, 4, 9, 1,\n",
       "        8, 3, 9, 6, 4, 0, 7, 3, 9, 6, 8, 8, 1, 7, 9, 8, 3, 5, 1, 2, 4, 5,\n",
       "        8, 3, 7, 4, 4, 7, 6, 0, 3, 5, 8, 3, 2, 9, 4, 3, 3, 6, 0, 5, 2, 1,\n",
       "        2, 6, 0, 9, 3, 1, 9, 2, 4, 5, 5, 5, 2, 2, 7, 3, 7, 9, 0, 7, 7, 6,\n",
       "        7, 0, 8, 9, 0, 6, 4, 8, 4, 5, 8, 4, 8, 7, 7, 9, 7, 2, 5, 7, 2, 9,\n",
       "        4, 8, 8, 3, 4, 5, 7, 8, 5, 1, 7, 4, 2, 7, 7, 9, 8, 2, 3, 2, 6, 9,\n",
       "        3, 9, 0, 0, 7, 1, 3, 0, 2, 6, 9, 5, 4, 5, 5, 7, 5, 4, 3, 1, 1, 5,\n",
       "        7, 7, 6, 4, 5, 2, 8, 5, 3, 4, 6, 3, 0, 7, 3, 8, 8, 8, 1, 1, 5, 2,\n",
       "        8, 5, 1, 2, 7, 1, 8, 1, 1, 1, 7, 6, 6, 4, 8, 2, 8, 2, 4, 1, 6, 3,\n",
       "        1, 2, 4, 4, 6, 3, 3, 3, 6, 1, 6, 0, 6, 1, 8, 2, 1, 1, 6, 5, 5, 1,\n",
       "        0, 4, 8, 8, 1, 3, 3, 1, 1, 8, 0, 3, 8, 4, 2, 0, 0, 2, 1, 2, 1, 5,\n",
       "        2, 0, 1, 8, 2, 3, 4, 3, 2, 1, 3, 3, 9, 7, 8, 0, 0, 9, 4, 5, 5, 7,\n",
       "        1, 6, 6, 0, 3, 0, 1, 4, 3, 5, 3, 8, 2, 9, 3, 9, 8, 6, 0, 9, 8, 1,\n",
       "        6, 8, 1, 1, 1, 4, 6, 9, 8, 0, 0, 8, 4, 5, 2, 1, 2, 4, 4, 3, 7, 5,\n",
       "        3, 2, 2, 7, 5, 3, 0, 1, 0, 9, 6, 9, 3, 7, 1, 2, 2, 0, 9, 3, 7, 0,\n",
       "        4, 9, 8, 5, 4, 4, 3, 9, 0, 4, 5, 9, 9, 4, 2, 6, 3, 9, 4, 5, 4, 2,\n",
       "        7, 8, 3, 7, 4, 0, 0, 2, 2, 4, 4, 7, 5, 8, 0, 0, 7, 9, 6, 2, 9, 7,\n",
       "        1, 9, 1, 6, 5, 0, 6, 4, 2, 8, 6, 1, 2, 0, 2, 0, 9, 1, 6, 0, 4, 1,\n",
       "        3, 5, 8, 8, 3, 0, 4, 6, 3, 9, 3, 2, 8, 9, 4, 7, 8, 4, 0, 5, 3, 8,\n",
       "        7, 4, 9, 8, 8, 6, 7, 2, 3, 8, 4, 0, 6, 7, 4, 8, 5, 1, 3, 2, 9, 8,\n",
       "        8, 7, 1, 0, 6, 9, 5, 5, 0, 6, 5, 3, 1, 5, 6, 9, 6, 8, 6, 3, 8, 2,\n",
       "        7, 9, 2, 3, 3, 7, 1, 9, 1, 6, 4, 6, 6, 1, 7, 2, 9, 0, 2, 5, 1, 8,\n",
       "        3, 3, 1, 7, 9, 2, 9, 2, 7, 9, 7, 1, 3, 4, 7, 6, 8, 3, 9, 1, 1, 5,\n",
       "        4, 1, 5, 2, 0, 2, 9, 9, 1, 1, 8, 3, 0, 0, 4, 1, 1, 9, 1, 7, 7, 2,\n",
       "        2, 0, 2, 6, 3, 1, 7, 1, 6, 3, 7, 7, 2, 4, 3, 9, 3, 1, 0, 7, 1, 9,\n",
       "        7, 9, 9, 2, 2, 9, 9, 9, 8, 5, 7, 7, 7, 7, 5, 6, 3, 8, 0, 9, 9, 1,\n",
       "        5, 8, 3, 7, 3, 2, 6, 6, 8, 0]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_transformed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    Xtrain,Xtest,Ytrain,Ytest = get_transformed_data()\n",
    "    print(\"Xtrain\",Xtrain.shape)\n",
    "    print(\"Xtest\",Xtest.shape)\n",
    "    print(\"Ytrain\",Ytrain.shape)\n",
    "    print(\"Ytest\",Ytest.shape) \n",
    "    \n",
    "    \n",
    "    N,D = Xtrain.shape #(41000, 300)\n",
    "    \n",
    "    #converting targets to indicators\n",
    "    Ytrain_ind = y2indicator(Ytrain)\n",
    "    Ytest_ind = y2indicator(Ytest)\n",
    "    print(Ytrain_ind.shape)#(41000, 10)\n",
    "    print(Ytest_ind.shape)#(1000, 10)\n",
    "    \n",
    "    \n",
    "    #1.Full \n",
    "    \n",
    "    w = np.random.randn(D,10)/np.sqrt(D)\n",
    "    b = np.zeros(10)\n",
    "    \n",
    "    LL = []\n",
    "    lr = 0.0001\n",
    "    reg = 0.01\n",
    "    t0 = datetime.now()\n",
    "    \n",
    "    \n",
    "    for i in range(50):\n",
    "        #training\n",
    "        p_y = forward(Xtrain,w,b)\n",
    "        \n",
    "        w += lr*(gradw(Ytrain_ind,p_y,Xtrain)-reg*w)\n",
    "        b += lr*(gradb(Ytrain_ind,p_y))\n",
    "        \n",
    "        \n",
    "        #testing\n",
    "        p_y_test = forward(Xtest,w,b)\n",
    "        \n",
    "        ll = cost(p_y_test,Ytest_ind)\n",
    "        LL.append(ll)\n",
    "        \n",
    "        \n",
    "        if i % 1 == 0:\n",
    "            err = error_rate(p_y_test,Ytest)\n",
    "            if i % 10 ==0:\n",
    "                print(\"iterations : \",i,\"cost:\",ll)\n",
    "                print(\"error rate\",err)\n",
    "                \n",
    "                \n",
    "                \n",
    "    p_y = forward(Xtest,w,b)\n",
    "    print(\"Final Error rate\",error_rate(p_y,Ytest))\n",
    "    print(\"time for FULL GD\",datetime.now()-t0)\n",
    "        \n",
    "        \n",
    "     #2 Stochastic\n",
    "    print(\"--------------------SGD------------------\")\n",
    "    \n",
    "    w = np.random.randn(D,10)/np.sqrt(D)\n",
    "    b = np.zeros(10)\n",
    "    \n",
    "    LL_stochastic = []\n",
    "    lr = 0.0001\n",
    "    reg = 0.01\n",
    "    t0 = datetime.now()\n",
    "    \n",
    "    \n",
    "    for i in range(50):\n",
    "        tmp_x,tmp_y =  shuffle(Xtrain,Ytrain_ind)\n",
    "        for n in range(min(N,500)):\n",
    "            x = tmp_x[n,:].reshape(1,D) # d= 300\n",
    "            y = tmp_y[n,:].reshape(1,10)\n",
    "            #print(x.shape) #(1,300)\n",
    "            #print(y.shape) #(1,10)\n",
    "            \n",
    "            \n",
    "            p_y = forward(x,w,b)\n",
    "            \n",
    "            \n",
    "            w += lr*(gradw(y,p_y,x)-reg*w)\n",
    "            b += lr*(gradb(y,p_y)-reg*b)\n",
    "            \n",
    "            \n",
    "            p_y_test = forward(Xtest,w,b)\n",
    "            ll = cost(p_y_test,Ytest_ind)\n",
    "            LL_stochastic.append(ll)\n",
    "            \n",
    "            \n",
    "        if i % 1 == 0 :\n",
    "            err = error_rate(p_y_test,Ytest)\n",
    "            if i % 10 == 0:\n",
    "                print(\"iterations : \",i,\"cost:\",ll)\n",
    "                print(\"error rate\",err)\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_y = forward(Xtest,w,b)\n",
    "    print(\"Final Error rate\",error_rate(p_y,Ytest))\n",
    "    print(\"time for stochastic GD\",datetime.now() - t0)\n",
    "\n",
    "\n",
    "    \n",
    "    # 3batch SGD\n",
    "    print(\"-----------------batchSGD--------------\")\n",
    "    \n",
    "    \n",
    "    w = np.random.randn(D,10)/np.sqrt(D)\n",
    "    b = np.zeros(10)\n",
    "    \n",
    "    LL_batch = []\n",
    "    lr = 0.0001\n",
    "    reg = 0.01\n",
    "    t0 = datetime.now()\n",
    "    \n",
    "    batch_sz = 500\n",
    "    n_batches = N // batch_sz # 82 batches(41000//500)\n",
    "    \n",
    "    \n",
    "    for i in range(50):\n",
    "        tmpX ,tmpY = shuffle(Xtrain,Ytrain_ind)\n",
    "        for j in range(n_batches):\n",
    "            x = tmpX[j*batch_sz:(j*batch_sz+batch_sz),:]\n",
    "            y = tmpY[j*batch_sz:(j*batch_sz+batch_sz),:]\n",
    "            \n",
    "            \n",
    "            p_y = forward(x,w,b)\n",
    "            \n",
    "            \n",
    "            w += lr*(gradw(y,p_y,x)-reg*w)\n",
    "            b += lr*(gradb(y,p_y)-reg*b)\n",
    "            \n",
    "            \n",
    "            p_y_test = forward(Xtest,w,b)\n",
    "            ll = cost(p_y_test,Ytest_ind)\n",
    "            LL_batch.append(ll)\n",
    "            \n",
    "            \n",
    "        if i % 1 == 0 :\n",
    "            err = error_rate(p_y_test,Ytest)\n",
    "            if i % 10 == 0:\n",
    "                print(\"iterations : \",i,\"cost:\",ll)\n",
    "                print(\"error rate\",err)\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_y = forward(Xtest,w,b)\n",
    "    print(\"Final Error rate\",error_rate(p_y,Ytest))\n",
    "    print(\"time for batch SGD  \",datetime.now() - t0)\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "Innputs [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "output [2 1 3 ... 2 8 4]\n",
      "(42000, 784)\n",
      "(42000,)\n",
      "Xtrain (41000, 784)\n",
      "Xtest (1000, 784)\n",
      "Ytrain (41000,)\n",
      "Ytest (1000,)\n",
      "(784,)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(41000, 784)\n",
      "(1000, 784)\n",
      "[[-4.9220078e+02 -9.7826886e+02 -3.7578781e+02 ...  4.5373477e-03\n",
      "   0.0000000e+00 -0.0000000e+00]\n",
      " [-6.6631573e+02 -7.6648834e+02  2.3083687e+02 ... -3.4883666e-05\n",
      "  -8.9716181e-05 -1.5983719e-04]\n",
      " [-2.0895137e+02 -4.8148972e+01 -7.7863306e+02 ...  3.3930846e-05\n",
      "  -1.4023611e-04  1.3109373e-03]\n",
      " ...\n",
      " [-6.9736313e+01  8.7773334e+02 -2.8877359e+02 ...  1.0224069e-06\n",
      "  -1.3298762e-07 -1.4830140e-07]\n",
      " [-1.9159558e+02  4.1660007e+02 -7.5348151e+02 ...  1.3132860e-06\n",
      "   1.0096221e-06 -2.1482249e-07]\n",
      " [ 1.1160231e+03 -8.1721234e+02 -4.8380405e+02 ... -7.4083346e-06\n",
      "  -5.5713838e-07  6.0984306e-08]]\n",
      "[[-1.0255625e+03 -5.2141064e+02  1.6038377e+02 ... -3.6609066e-07\n",
      "   1.2955857e-04 -9.7597556e-05]\n",
      " [-9.5968475e+02 -4.9191492e+02  1.3668813e+02 ... -5.4430707e-06\n",
      "   7.8254794e-05 -1.5842270e-04]\n",
      " [ 5.2989844e+02 -7.3830798e+02 -2.6566321e+02 ... -2.0988468e-06\n",
      "  -7.9177989e-05 -1.6084243e-05]\n",
      " ...\n",
      " [-6.1381622e+01  4.4894012e+02  1.6446899e+02 ...  2.1932319e-06\n",
      "  -8.4609062e-05  3.2541991e-04]\n",
      " [-1.5057069e+02 -2.6530469e+02  1.5517507e+01 ...  4.0061359e-06\n",
      "  -9.2149749e-05 -1.6372291e-04]\n",
      " [-6.2379834e+02  3.9595615e+02 -6.7468651e+01 ...  2.7534536e-06\n",
      "  -9.0737864e-05  1.5624704e-05]]\n",
      "(41000, 300)\n",
      "(1000, 300)\n",
      "Xtrain (41000, 300)\n",
      "Xtest (1000, 300)\n",
      "Ytrain (41000,)\n",
      "Ytest (1000,)\n",
      "(41000, 10)\n",
      "(1000, 10)\n",
      "iterations :  0 cost: 990.5059970848654\n",
      "error rate 0.242\n",
      "iterations :  10 cost: 368.5127002865249\n",
      "error rate 0.092\n",
      "iterations :  20 cost: 331.28221158189524\n",
      "error rate 0.086\n",
      "iterations :  30 cost: 316.91205315815296\n",
      "error rate 0.082\n",
      "iterations :  40 cost: 309.3920316251472\n",
      "error rate 0.079\n",
      "Final Error rate 0.079\n",
      "time for FULL GD 0:00:10.887497\n",
      "--------------------SGD------------------\n",
      "iterations :  0 cost: 2660.1427194695802\n",
      "error rate 0.898\n",
      "iterations :  10 cost: 2386.734758269507\n",
      "error rate 0.834\n",
      "iterations :  20 cost: 2139.944270293874\n",
      "error rate 0.748\n",
      "iterations :  30 cost: 1923.7514358814615\n",
      "error rate 0.672\n",
      "iterations :  40 cost: 1736.0814230394428\n",
      "error rate 0.575\n",
      "Final Error rate 0.481\n",
      "time for stochastic GD 0:01:23.836449\n",
      "-----------------batchSGD--------------\n",
      "iterations :  0 cost: 1205.8977745129168\n",
      "error rate 0.291\n",
      "iterations :  10 cost: 380.15124928270836\n",
      "error rate 0.089\n",
      "iterations :  20 cost: 335.8173099850403\n",
      "error rate 0.086\n",
      "iterations :  30 cost: 319.6313000965319\n",
      "error rate 0.084\n",
      "iterations :  40 cost: 311.2526425335359\n",
      "error rate 0.082\n",
      "Final Error rate 0.08\n",
      "time for batch SGD   0:00:32.999773\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "41000//500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
